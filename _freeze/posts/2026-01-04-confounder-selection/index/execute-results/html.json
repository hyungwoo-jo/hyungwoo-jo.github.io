{
  "hash": "6973a6353d651f6e3c16e869e6c15adc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Inference (3): Confounder Selection & Collider Bias\"\ndescription: \"교란변수는 어떻게 선택해야 하나: data-driven의 함정과 collider\"\nimage: img/image.jpeg\ncategories: [statistics, causal-inference, R]\nauthor:\n  - name: Hyungwoo Jo\n    url: https://github.com/hyungwoo-jo\nfig_width: 400\ndate: 2026-01-04\nformat: html\nexecute:\n  freeze: auto\ndraft: false\ncitation: true\n---\n\n\n\n앞선 글에서는 성향점수(PSM, IPTW)로 “치료군과 대조군을 비교 가능하게 만드는 방법”을 다뤘다. 그런데 성향점수든 회귀 보정이든, 결국 한 가지 질문으로 수렴한다. **무엇을 보정해야 하는가?**\n\n많은 의학 논문에서 공변량은 관행적으로 선택된다. 예컨대 공변량 후보를 여러 개 두고 결과와의 연관성을 p-value로 훑은 뒤(p\\<0.1 같은 기준), 남은 변수들로 다변량 모델을 구성하거나, forward/backward stepwise로 “최종 모델”을 만든다. 이런 방식이 등장하는 이유는 현실적이다. 표본이나 사건 수가 제한적이면 과적합이 걱정되고, 공변량 후보는 끝없이 늘어나며, “유의한 것만 남기는 모델”이 깔끔해 보이기 때문이다.\n\n하지만 인과추론에서 변수 선택은 “예측이 잘 되는 모델”을 고르는 문제가 아니다. 우리가 추정하려는 것은 $T \\rightarrow Y$ 인과효과이고, 조정의 목적은 **backdoor path를 닫아 편향을 줄이는 것**이다. 특히 **collider(충돌 변수)**를 조정하거나, collider로 표본을 제한하면 편향이 “줄어드는” 것이 아니라 “새로 생길 수” 있다. 예측에는 도움이 되는 변수가 인과추정에는 위험한 변수가 되는 순간이다.\n\n이 글에서는 먼저 의학 연구에서 흔한 data-driven confounder 선택 관행을 정리하고, collider가 왜 위험한지 설명한 뒤, R 시뮬레이션으로 “전통적 방법이 collider를 포함해 결과를 왜곡하는” 상황을 보여준다. 마지막으로 현실적으로 가장 이상적인 접근(knowledge-driven)을 정리해보겠다.\n\n------------------------------------------------------------------------\n\n## 1. Confounder를 고르는 문제는 “통계”가 아니라 “인과”다\n\n교란변수는 간단히 말해 **치료/노출(**$T$)과 결과($Y$) 모두에 영향을 주는 변수다. 예를 들어 “흡연이 HbA1c를 올리는가?”를 보고 싶다면, 나이·성별·운동·식습관·음주 같은 변수는 흡연과 HbA1c 모두와 연관될 수 있다. 이때 단순 비교는 “흡연 효과”가 아니라 “기본 특성 차이”를 섞어서 보게 된다.\n\n그래서 우리는 $T$와 $Y$ 사이의 비교가 “교환가능성(exchangeability)”에 가까워지도록 공변량을 조정한다. 그런데 여기서 핵심은, 공변량 선택이 “결과와 상관이 있는 변수”를 찾는 문제가 아니라, $T \\rightarrow Y$ 인과효과를 추정할 때 열려 있는 backdoor path를 닫는 문제라는 점이다.\n\n------------------------------------------------------------------------\n\n## 2. 의학 연구에서 흔한 data-driven 선택: p-value, forward/backward stepwise\n\n현장에서 자주 보는 방식은 크게 두 가지다.\n\n첫째는 univariate screening이다. 공변량 후보를 하나씩 결과와 연결해 보고(p-value), 일정 기준을 넘는 변수만 “후보”로 올린 뒤 다변량 모델을 만든다. 둘째는 stepwise selection이다. 후보 변수를 넣고 빼며 AIC(또는 p-value 기준)로 “가장 잘 맞는 모델”을 자동으로 고르는 방식이다. 이런 방법이 쓰이는 이유는 이해할 수 있다. 연구자는 “너무 많은 변수를 넣어 불안정해지는 것”을 피하고 싶고, 독자는 “최종 모델이 뭔지”를 보고 싶어한다.\n\n이 과정에서 “p-value 기준으로 너무 많은 변수를 테스트했으니 다중비교 보정(FDR 등)을 해야 하는 것 아닌가?”라는 질문이 자연스럽게 따라온다. 하지만 confounder 선택의 핵심 문제는 “유의성 검정의 엄격함”이 아니다. p-value를 더 보수적으로 만든다고 해서, 인과추정에 해로운 변수가 안전해지는 것도 아니고, 반대로 중요한 confounder가 자동으로 살아남는 것도 아니다. 특히 표본이 크면 작은 차이도 쉽게 유의해지고, 표본이 작으면 중요한 교란이 유의하지 않게 보이기도 한다.\n\n더 근본적으로, confounding은 “그 변수가 결과를 잘 예측하는가?”가 아니라 “치료/노출과 결과 사이의 비교를 왜곡하는 경로를 닫는가?”의 문제다. 어떤 변수는 결과 예측력은 약해 보여도(유의하지 않아도) 치료와 결과에 동시에 관련되어 편향을 크게 만들 수 있고, 반대로 결과와 강하게 관련되어 매우 유의해도(예측자여도) collider/매개변수라면 조정하는 순간 편향을 만든다.\n\n즉, 이런 절차가 공통적으로 “예측이 잘 되는 변수”를 선호한다는 점이 문제의 출발점이다. 그리고 예측이 잘 되는 변수 중에는, 인과추정에 넣는 순간 오히려 편향을 만드는 변수가 있다. 대표적인 것이 collider다.\n\n------------------------------------------------------------------------\n\n## 3. Collider가 왜 위험한가: HbA1c 예시로 연결하기\n\ncollider는 DAG에서 두 화살표가 한 변수로 “충돌”하는 구조다.\n\n\n\n```{mermaid}\ngraph LR\nS[Smoking] --> H[Heart disease]\nU[Unmeasured metabolic risk] --> H\nU --> A[HbA1c]\nS --> A\n```\n\n\n\n이 그림에서 heart disease($H$)는 흡연($S$)과 관측되지 않은 대사 위험도($U$)의 “공통 결과”다. $U$는 HbA1c($A$)에도 영향을 준다. 이때 heart disease를 조정하거나, “심장병이 있는 사람만” 분석하면 $S \\rightarrow H \\leftarrow U \\rightarrow A$ 경로가 열려서 흡연과 HbA1c 사이의 관계가 왜곡될 수 있다.\n\n현장에서 이 오류가 생기는 전형적인 장면은 다음과 같다. 심장병은 예후적으로 중요하고, 데이터에도 잘 기록되어 있으며, 결과(HbA1c)와도 강하게 연관된다. 그래서 p-value screening이나 stepwise selection은 심장병 변수를 쉽게 “좋은 공변량”으로 선택한다. 하지만 그 변수가 collider라면, 그 순간 인과추정은 삐끗한다.\n\n말로만 들으면 직관이 약하니, 시뮬레이션으로 확인해보자.\n\n------------------------------------------------------------------------\n\n## 4. R 시뮬레이션: 전통적 선택이 collider를 끼워 넣는 순간\n\n아래 시뮬레이션은 “흡연이 HbA1c를 약간 올린다(진짜 효과는 +0.20)”를 진실로 설정하고, 나이·성별·운동·식습관·음주 같은 기본 특성은 흡연과 HbA1c 모두에 영향을 주는 교란변수로 만든다. 그리고 heart disease는 흡연과 관측되지 않은 대사 위험도($U$)에 의해 생기는 collider로 설정한다.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nset.seed(20260104)\n\ncoef_ci <- function(fit, term = \"smoking\") {\n  co <- coef(summary(fit))\n  est <- co[term, \"Estimate\"]\n  se <- co[term, \"Std. Error\"]\n  tibble(estimate = est, lo = est - 1.96 * se, hi = est + 1.96 * se)\n}\n\nn <- 100000\nage <- rnorm(n, mean = 60, sd = 10)\nsex <- rbinom(n, 1, 0.5) # 1=male\n\nactivity <- rnorm(n)  # 높을수록 활동적\ndiet <- rnorm(n)      # 높을수록 식습관 양호\nalcohol <- rbinom(n, 1, plogis(-0.3 + 0.02 * (age - 60) + 0.2 * sex))\n\n# 관측되지 않은 대사 위험도 (유전/비만/염증/사회경제 등)\nu <- rnorm(n)\n\n# 흡연(노출): 기본 특성에 의해 선택(교란 존재)\nsmoking <- rbinom(\n  n, 1,\n  plogis(-0.2 + 0.03 * (age - 60) + 0.3 * sex + 0.4 * alcohol - 0.5 * activity - 0.3 * diet)\n)\n\n# Outcome: HbA1c\ntrue_tau <- 0.20\nhba1c <- 6.8 +\n  true_tau * smoking +\n  0.03 * (age - 60) +\n  0.10 * sex +\n  0.12 * alcohol -\n  0.12 * activity -\n  0.10 * diet +\n  0.80 * u +\n  rnorm(n, 0, 0.6)\n\n# Collider: 심혈관질환은 smoking과 u의 공통 결과\nheart_disease <- rbinom(n, 1, plogis(-3.2 + 2.0 * smoking + 2.0 * u + 0.04 * (age - 60) + 0.3 * alcohol))\n\ndf <- tibble(age, sex, activity, diet, alcohol, smoking, heart_disease, hba1c)\n\nfit_naive <- lm(hba1c ~ smoking, data = df)\nfit_knowledge <- lm(hba1c ~ smoking + age + sex + activity + diet + alcohol, data = df)\nfit_plus_collider <- lm(hba1c ~ smoking + age + sex + activity + diet + alcohol + heart_disease, data = df)\n\nbind_rows(\n  coef_ci(fit_naive) %>% mutate(model = \"naive\"),\n  coef_ci(fit_knowledge) %>% mutate(model = \"knowledge-driven adjustment\"),\n  coef_ci(fit_plus_collider) %>% mutate(model = \"knowledge + collider\")\n) %>%\n  mutate(true_tau = true_tau) %>%\n  select(model, estimate, lo, hi, true_tau)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  model                       estimate      lo       hi true_tau\n  <chr>                          <dbl>   <dbl>    <dbl>    <dbl>\n1 naive                         0.391   0.378   0.404        0.2\n2 knowledge-driven adjustment   0.205   0.192   0.218        0.2\n3 knowledge + collider         -0.0161 -0.0284 -0.00393      0.2\n```\n\n\n:::\n:::\n\n\n\n여기서 `knowledge-driven adjustment`는 “치료 이전에 측정되는 기본 특성”만 조정한다. 반대로 `knowledge + collider`는 심혈관질환을 추가로 조정한다. 이 차이로 인해 효과가 단순히 약해지는 수준을 넘어, 상황에 따라서는 **효과 방향(부호) 자체가 바뀔 수도** 있음을 확인할 수 있다.\n\n------------------------------------------------------------------------\n\n## 5. 전통적 절차를 그대로 따라하면(스크리닝/stepwise) 무슨 일이 생길까?\n\n이제 흔한 관행을 그대로 흉내 내보자. 첫 번째는 univariate screening이고, 두 번째는 forward/backward stepwise(AIC)다. 둘 다 결과를 잘 설명하는 변수를 선호하므로, heart disease처럼 결과와 강하게 연관된 변수가 있으면 쉽게 포함될 수 있다.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncandidate_vars <- c(\"age\", \"sex\", \"activity\", \"diet\", \"alcohol\", \"heart_disease\")\n\n# (1) univariate screening: hba1c ~ smoking + x 에서 x의 p-value로 선택\npvals <- map_dbl(candidate_vars, function(v) {\n  f <- as.formula(paste0(\"hba1c ~ smoking + \", v))\n  fit <- lm(f, data = df)\n  coef(summary(fit))[v, \"Pr(>|t|)\"]\n})\nnames(pvals) <- candidate_vars\nselected <- names(pvals)[pvals < 0.1]\nselected\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"age\"           \"sex\"           \"activity\"      \"diet\"         \n[5] \"alcohol\"       \"heart_disease\"\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_screened <- lm(as.formula(paste(\"hba1c ~ smoking +\", paste(selected, collapse = \" + \"))), data = df)\n\n# (2) stepwise (forward/backward, AIC)\nfit_full <- lm(hba1c ~ smoking + age + sex + activity + diet + alcohol + heart_disease, data = df)\nfit_step <- step(fit_full, direction = \"both\", trace = 0)\nformula(fit_step)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhba1c ~ smoking + age + sex + activity + diet + alcohol + heart_disease\n```\n\n\n:::\n\n```{.r .cell-code}\nbind_rows(\n  coef_ci(fit_knowledge) %>% mutate(model = \"knowledge-driven adjustment\"),\n  coef_ci(fit_screened) %>% mutate(model = \"p-value screening\"),\n  coef_ci(fit_step) %>% mutate(model = \"stepwise (AIC)\")\n) %>%\n  mutate(true_tau = true_tau) %>%\n  select(model, estimate, lo, hi, true_tau)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  model                       estimate      lo       hi true_tau\n  <chr>                          <dbl>   <dbl>    <dbl>    <dbl>\n1 knowledge-driven adjustment   0.205   0.192   0.218        0.2\n2 p-value screening            -0.0161 -0.0284 -0.00393      0.2\n3 stepwise (AIC)               -0.0161 -0.0284 -0.00393      0.2\n```\n\n\n:::\n:::\n\n\n\n이 실험에서 핵심은 “어떤 변수가 선택되는가”다. heart disease는 결과(HbA1c)와 강하게 연관되기 때문에, 스크리닝/stepwise에서 자주 살아남는다. 그런데 heart disease가 collider라면, “유의한 공변량을 잘 골랐다”는 직감과 달리 흡연 효과 추정이 0에 가까워지거나 심지어 반대 방향으로 왜곡될 수 있다.\n\n아래 그림은 각 접근이 추정한 흡연 효과를 한눈에 비교한 것이다. (진짜 효과는 +0.20으로 설정했다.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest_tbl <- bind_rows(\n  coef_ci(fit_naive) %>% mutate(model = \"naive\"),\n  coef_ci(fit_knowledge) %>% mutate(model = \"knowledge-driven\"),\n  coef_ci(fit_plus_collider) %>% mutate(model = \"knowledge + collider\"),\n  coef_ci(fit_screened) %>% mutate(model = \"p-value screening\"),\n  coef_ci(fit_step) %>% mutate(model = \"stepwise (AIC)\")\n) %>%\n  mutate(model = factor(model, levels = rev(unique(model))))\n\nggplot(est_tbl, aes(x = estimate, y = model)) +\n  geom_vline(xintercept = true_tau, linetype = 2, alpha = 0.7) +\n  geom_pointrange(aes(xmin = lo, xmax = hi)) +\n  labs(x = \"Estimated effect of smoking on HbA1c\", y = NULL)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## 6. 결론: 가장 이상적인 접근은 knowledge-driven이다\n\n인과추론에서 confounder 선택은 통계적 ‘모형 선택’이 아니라, **시간축과 지식에 기반한 설계 선택**이어야 한다. 가능한 한 치료(노출) 이전에 측정된 변수만 후보로 두고, 임상/역학적 지식으로 인과 구조를 정리한 뒤(DAG), backdoor path를 닫는 조정 집합을 명시하는 것이 출발점이다. 예후가 중요해 보이는 변수라도 그것이 치료 이후 변수이거나 collider 가능성이 있다면(예: 합병증, 입원, 검사 시행, 중증도 지표 등), 조정에 포함시키는 순간 편향이 새로 생길 수 있음을 항상 염두에 두는 편이 안전하다.\n\n그리고 평균 효과 한 줄로 끝내기 전에, 효과 이질성(예: 나이/성별/생활습관에 따른 차이)을 확인하는 습관도 중요하다. ITE는 정의상 직접 관측되지 않지만, CATE처럼 “조건부 평균 효과”는 현실 데이터에서 훨씬 실용적인 형태로 접근할 수 있다. 결국 “무엇을 보정할 것인가”는 곧 “무엇을 알고 싶은가”와 연결되고, 그 질문을 정확히 고정하는 것에서 인과추론이 시작된다.\n\n다음 글에서는 DAG를 이용해 조정 집합을 고르는 실전적인 규칙들과(예: backdoor criterion, time ordering) 현실 데이터에서 collider/mediator 후보를 구별하는 감각을 더 구체적으로 다뤄보겠다.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}