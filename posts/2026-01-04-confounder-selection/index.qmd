---
title: "Causal Inference (3): Confounder Selection & Collider Bias"
description: "교란변수는 어떻게 선택해야 하나: data-driven의 함정과 collider"
image: img/image.jpeg
categories: [statistics, causal-inference, R]
author:
  - name: Hyungwoo Jo
    url: https://github.com/hyungwoo-jo
fig_width: 400
date: 2026-01-04
format: html
execute:
  freeze: auto
draft: false
citation: true
---

앞선 글에서는 성향점수(PSM, IPTW)로 “치료군과 대조군을 비교 가능하게 만드는 방법”을 다뤘다. 그런데 성향점수든 회귀 보정이든, 결국 한 가지 질문으로 수렴한다. **무엇을 보정해야 하는가?** 의학 연구에서 가장 흔한 함정은 “많이 보정하면 안전하다”는 직감인데, 실제로는 정반대인 경우가 있다. 특히 **collider를 보정(혹은 그 collider로 조건을 걸어 표본을 제한)하면 편향이 새로 생길 수 있다.**

이 글에서는 (1) 교란변수(confounder)와 조정(adjustment)의 핵심을 정리하고, (2) 데이터 기반 변수 선택(p-value screening, stepwise selection 등)이 왜 위험한지, (3) collider bias가 어떻게 생기는지 R 시뮬레이션으로 보여준 뒤, (4) 현실적으로 무엇이 “가장 이상적인” 접근인지까지 정리해보겠다.

------------------------------------------------------------------------

## 1. Confounder를 고르는 문제는 “통계”가 아니라 “인과”다

교란변수는 간단히 말해 **치료 할당($T$)과 결과($Y$) 모두에 영향을 주는 변수**다. 예를 들어 앞 글의 판막질환 예시에서 “수술 vs 시술”을 비교할 때, **나이**는 치료 선택에도 영향을 주고(고령일수록 시술), 사망률에도 영향을 준다(고령일수록 사망). 이때 단순 비교는 “치료 효과”가 아니라 “나이 차이”를 섞어서 보게 된다.

그래서 우리는 $T$와 $Y$ 사이의 비교가 “교환가능성(exchangeability)”에 가까워지도록 공변량을 조정한다. 그런데 여기서 핵심은, 공변량 선택이 “결과와 상관이 있는 변수”를 찾는 문제가 아니라, **$T \rightarrow Y$ 인과효과를 추정할 때 열려 있는 backdoor path를 닫는 문제**라는 점이다.

------------------------------------------------------------------------

## 2. Collider가 왜 중요한가

collider는 DAG에서 두 화살표가 한 변수로 “충돌”하는 구조다. 대표적인 형태는 아래와 같다.

```{mermaid}
graph LR
T[Treatment] --> K[Collider]
U[Unmeasured risk] --> K
U --> Y[Outcome]
```

여기서 $K$는 “치료($T$)와 잠재적 위험도($U$)의 결과로 결정되는 변수”다. 판막질환 예시로 번역하면 다음처럼 생각할 수 있다.

“ICU 입실 여부”는 **수술을 했기 때문**에도 증가할 수 있고, **기저 위험도(취약성/중증도)가 높기 때문**에도 증가할 수 있다. 그리고 그 기저 위험도는 사망률($Y$)에도 영향을 준다. 이때 ICU 입실($K$)을 조정하거나, ‘ICU에 입실한 환자만’ 분석하면, 원래 닫혀 있던 경로가 열리면서 $T$와 $Y$ 사이에 가짜 연관이 생길 수 있다.

말로만 들으면 직관이 잘 안 오므로, 아래에서 바로 시뮬레이션으로 확인해보자.

------------------------------------------------------------------------

## 3. R 예시 1: “교란”은 보정하면 줄어든다

먼저 confounding이 있는 상황을 만들자. (진짜 치료 효과는 0으로 설정)

```{r, message=FALSE, warning=FALSE}
library(tidyverse)

set.seed(20260104)

or_ci <- function(fit, term = "treat") {
  co <- coef(summary(fit))
  est <- co[term, "Estimate"]
  se <- co[term, "Std. Error"]
  tibble(
    OR = exp(est),
    lo = exp(est - 1.96 * se),
    hi = exp(est + 1.96 * se)
  )
}

n <- 50000
age <- rnorm(n, mean = 70, sd = 10)

# 젊을수록 수술(treat=1) 확률이 높게 (confounding)
treat <- rbinom(n, 1, plogis(5 - 0.07 * age))

# true effect of treat is 0; age만 사망에 영향
mortality <- rbinom(n, 1, plogis(-6 + 0.08 * age))

df1 <- tibble(age, treat, mortality)

fits <- list(
  naive = glm(mortality ~ treat, data = df1, family = binomial()),
  adjust_age = glm(mortality ~ treat + age, data = df1, family = binomial())
)

bind_rows(
  or_ci(fits$naive) %>% mutate(model = "naive (no adjustment)"),
  or_ci(fits$adjust_age) %>% mutate(model = "adjust age")
) %>% select(model, everything())
```

이 예시는 “치료 효과가 없다”는 사실을 알고 만드는 데이터다. 그런데도 나이를 조정하지 않으면 치료 효과가 있는 것처럼 보일 수 있다. 이런 상황에서는 confounder(여기서는 age)를 조정하는 것이 편향을 줄인다.

------------------------------------------------------------------------

## 4. R 예시 2: “collider”는 보정하면 오히려 편향이 생긴다

이번에는 진짜 치료 효과가 없는 상황에서, collider를 조정(혹은 표본 제한)했을 때 어떤 일이 생기는지 보자.

```{r, message=FALSE, warning=FALSE}
set.seed(20260104)

n <- 200000
u <- rnorm(n)                     # 관측되지 않은 위험도(취약성)
treat <- rbinom(n, 1, 0.5)        # 치료는 무작위(교란 없음)

# 결과는 u에만 의존 (treat 효과=0)
mortality <- rbinom(n, 1, plogis(-2.2 + 1.0 * u))

# ICU 입실(collier): treat와 u가 모두 영향을 줌
icu <- rbinom(n, 1, plogis(-1.3 + 1.2 * treat + 1.2 * u))

df2 <- tibble(treat, mortality, icu)

fit_unadjusted <- glm(mortality ~ treat, data = df2, family = binomial())
fit_adjust_collider <- glm(mortality ~ treat + icu, data = df2, family = binomial())
fit_in_icu <- glm(mortality ~ treat, data = df2 %>% filter(icu == 1), family = binomial())

bind_rows(
  or_ci(fit_unadjusted) %>% mutate(model = "unadjusted (correct here)"),
  or_ci(fit_adjust_collider) %>% mutate(model = "adjust collider (ICU)"),
  or_ci(fit_in_icu) %>% mutate(model = "restrict to ICU==1")
) %>% select(model, everything())
```

여기서 치료는 무작위였고, 진짜 치료 효과는 0이다. 따라서 `unadjusted`가 오히려 “정답에 가까운” 추정을 한다. 반대로 ICU($K$)를 조정하거나 ICU 환자만 분석하면(조건부 분석), $T \rightarrow K \leftarrow U \rightarrow Y$ 경로가 열리면서 가짜 효과가 생길 수 있다. 이것이 collider bias다.

------------------------------------------------------------------------

## 5. “데이터 기반 변수 선택”이 collider를 끼워 넣는 방식

실전에서 collider가 자주 끼어드는 경로는 의외로 단순하다. “예후가 나쁜 환자는 ICU를 간다”는 이유로 ICU 입실 여부가 outcome과 강하게 연관이 있고, p-value screening이나 stepwise selection은 이런 변수를 “좋은 예측자”로 선택하기 쉽다. 그런데 ICU는 종종 치료 이후의 변수이거나, 치료와 위험도의 결과(collier)일 수 있다. 즉, **예측에는 도움이 되지만 인과추정에는 해로운 변수**가 된다.

그래서 confounder 선택은 “유의한 변수만 넣자”가 아니라, 시간 순서(치료 이전/이후)와 인과 구조(DAG)를 기준으로 해야 한다. 특히 판막질환 예시에서는 “합병증, ICU 입실, 수혈, 재수술, 검사 시행 여부”처럼 치료 이후에 결정될 수 있는 변수는 조정 대상이 아니거나(매개변수/후행변수), 오히려 조정하면 편향을 키울 수 있는 후보(collier)라는 점을 항상 의심해야 한다.

------------------------------------------------------------------------

## 6. 요약: 이상적인 접근(현실적으로 가능한 형태)

실전에서 가장 이상적인 흐름은 “지식 기반(knowledge-driven)”이다. 먼저 임상의/도메인 지식으로 시간축을 고정하고, 치료 이전에 측정 가능한 변수들 중에서 “치료와 결과 모두에 영향을 주는” 후보를 생각해 DAG로 구조를 정리한다. 그 다음 backdoor path를 닫는 최소 조정 집합(minimal adjustment set)을 명시하고, 그 집합을 중심으로 분석한다. 마지막으로 positivity(모든 공변량 수준에서 두 치료가 모두 어느 정도 선택되는가)와 극단적인 가중치 여부를 점검하고, 필요한 경우 trimming/overlap 기반의 민감도 분석까지 함께 보고 결론의 안정성을 확인한다.

치료 효과가 나이 같은 공변량에 따라 달라질 수 있다는 점도 같이 기억해야 한다. 한 개인 $i$의 ITE는 $Y_i(1)-Y_i(0)$로 정의되지만 직접 관측되지 않으므로, 실제로는 CATE처럼 “조건부 평균 효과”를 통해 하위 집단별로 효과를 요약하는 방식이 실용적이다. 결국 평균 효과(ATE/ATT) 한 줄만으로 결론내리기 전에, 어떤 집단에서 효과가 달라지는지까지 함께 보는 것이 의학적 해석에 더 가깝다.

다음 편에서는 그렇다면 어떤 변수를 교란변수로 보고(혹은 보지 않고), 어떤 원칙으로 조정 집합을 선택해야 하는지에 대해 더 깊게 들어가 보겠다.

